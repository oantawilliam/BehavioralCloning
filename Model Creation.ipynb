{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import csv\n",
    "import glob \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Default Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process default data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_csv = './default_data/driving_log.csv'\n",
    "path = './default_data/'\n",
    "\n",
    "car_images = []\n",
    "steering_angles = []\n",
    "\n",
    "# Get first track csv data\n",
    "with open(default_csv) as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    \n",
    "    for row in reader:\n",
    "        \n",
    "        if row[3] == \"steering\":\n",
    "            continue\n",
    "            \n",
    "        steering_center = float(row[3])\n",
    "\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "        correction = 0.2 # this is a parameter to tune\n",
    "        steering_left = steering_center + correction\n",
    "        steering_right = steering_center - correction\n",
    "\n",
    "        # read in images from center, left and right cameras\n",
    "        img_center = cv2.imread(path + row[0].strip())\n",
    "        img_left = cv2.imread(path + row[1].strip())\n",
    "        img_right = cv2.imread(path + row[2].strip())\n",
    "        \n",
    "        # add images and angles to data set\n",
    "        car_images.extend([img_center, img_left, img_right])\n",
    "        steering_angles.extend([steering_center, steering_left, steering_right])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training data set\n",
    "X_train_d = np.array(car_images)\n",
    "y_train_d = np.array(steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_train_data = {\"features\" : X_train_d,\"labels\" : y_train_d}\n",
    "pickle.dump(default_train_data, open( \"default_train.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "invalid file: <_io.TextIOWrapper name='./default_data/driving_log.csv' mode='r' encoding='ANSI_X3.4-1968'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-91fa2b8aebd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0msteering_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid file: <_io.TextIOWrapper name='./default_data/driving_log.csv' mode='r' encoding='ANSI_X3.4-1968'>"
     ]
    }
   ],
   "source": [
    "with open(csv_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            steering_center = float(row[3])\n",
    "default_img = './default_data/IMG'\n",
    "            # create adjusted steering measurements for the side camera images\n",
    "            correction = 0.2 # this is a parameter to tune\n",
    "            steering_left = steering_center + correction\n",
    "            steering_right = steering_center - correction\n",
    "\n",
    "            # read in images from center, left and right cameras\n",
    "            path = \"...\" # fill in the path to your training IMG directory\n",
    "            img_center = process_image(np.asarray(Image.open(path + row[0])))\n",
    "            img_left = process_image(np.asarray(Image.open(path + row[1])))\n",
    "            img_right = process_image(np.asarray(Image.open(path + row[2])))\n",
    "\n",
    "            # add images and angles to data set\n",
    "            car_images.extend(img_center, img_left, img_right)\n",
    "            steering_angles.extend(steering_center, steering_left, steering_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Recorded Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process CSV measurements file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5315\n"
     ]
    }
   ],
   "source": [
    "# Tracks directories\n",
    "first_track = './data/first_track'\n",
    "second_track = './data/second_track'\n",
    "\n",
    "log_file = 'driving_log.csv'\n",
    "imgs_folder = 'IMG'\n",
    "log_csv = []\n",
    "\n",
    "# List used to skip some data\n",
    "valid_folders = ['center_lane_1', \n",
    "                 'curves_smoothly_1_f_1', \n",
    "                 'curves_smoothly_1_f_2', \n",
    "                 'recovery_1',\n",
    "                 'center_lane_2', \n",
    "                 'curves_smoothly_2_f', \n",
    "                 'recovery_2']\n",
    "\n",
    "# Get first track csv data\n",
    "for file in os.listdir(first_track):\n",
    "    if file in valid_folders:\n",
    "        # Build CSV path\n",
    "        csv_path = \"{}/{}/{}\".format(first_track, file, log_file)\n",
    "\n",
    "        # Load CSV data\n",
    "        with open(csv_path) as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            for line in reader:\n",
    "                log_csv.append(line)\n",
    "\n",
    "# Get second track csv data\n",
    "for file in os.listdir(second_track):\n",
    "    if file in valid_folders:\n",
    "        \n",
    "        # Build CSV path\n",
    "        csv_path = \"{}/{}/{}\".format(second_track, file, log_file)\n",
    "\n",
    "        # Load CSV data\n",
    "        with open(csv_path) as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            for line in reader:\n",
    "                log_csv.append(line)\n",
    "\n",
    "print(len(log_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5315\n",
      "5315\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "measurements = []\n",
    "\n",
    "for line in log_csv:\n",
    "    # Get image path\n",
    "    source_path = line[0]\n",
    "    # Get image name\n",
    "    file_name = source_path.split('/')[-1]\n",
    "    # Change image path \n",
    "    current_path = './data/IMG/' + file_name\n",
    "    # Store Image\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    \n",
    "    # Store Steering Angle\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "\n",
    "# Build training data set\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Training Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = {\"features\" : X_train,\"labels\" : y_train}\n",
    "pickle.dump(train_data, open( \"train.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"train.p\", \"rb\") as train_file:\n",
    "    train_data = pickle.load(train_file)\n",
    "    \n",
    "X_train, y_train = train_data[\"features\"], train_data[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplest Model Possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Cropping2D, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adamax, Adadelta, Adagrad, Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplest Model Try Out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17516 samples, validate on 4379 samples\n",
      "Epoch 1/10\n",
      "17516/17516 [==============================] - 20s - loss: 1633333.1567 - val_loss: 1195.7598\n",
      "Epoch 2/10\n",
      "17516/17516 [==============================] - 20s - loss: 2928.4181 - val_loss: 8850.5901\n",
      "Epoch 3/10\n",
      "17516/17516 [==============================] - 20s - loss: 154086.9365 - val_loss: 19758618.6120\n",
      "Epoch 4/10\n",
      "17516/17516 [==============================] - 20s - loss: 559733.1857 - val_loss: 4464.4862\n",
      "Epoch 5/10\n",
      "17516/17516 [==============================] - 20s - loss: 374218.4078 - val_loss: 25923.1692\n",
      "Epoch 6/10\n",
      "17516/17516 [==============================] - 20s - loss: 292226.3216 - val_loss: 54597.8005\n",
      "Epoch 7/10\n",
      "17516/17516 [==============================] - 20s - loss: 203483.8062 - val_loss: 45812.6437\n",
      "Epoch 8/10\n",
      "17516/17516 [==============================] - 20s - loss: 414011.9327 - val_loss: 5974.0142\n",
      "Epoch 9/10\n",
      "17516/17516 [==============================] - 20s - loss: 355963.7128 - val_loss: 73384.6647\n",
      "Epoch 10/10\n",
      "17516/17516 [==============================] - 20s - loss: 259130.7647 - val_loss: 392413.5940\n"
     ]
    }
   ],
   "source": [
    "m1 = Sequential()\n",
    "m1.add(Flatten(input_shape=(160, 320, 3)))\n",
    "m1.add(Dense(1))\n",
    "\n",
    "m1.compile(loss='mse', optimizer='adam')\n",
    "m1.fit(X_train, y_train, validation_split=0.2, shuffle=True)\n",
    "\n",
    "m1.save('m1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Images in Range: 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17516 samples, validate on 4379 samples\n",
      "Epoch 1/10\n",
      "17516/17516 [==============================] - 20s - loss: 25.9219 - val_loss: 0.1310\n",
      "Epoch 2/10\n",
      "17516/17516 [==============================] - 20s - loss: 0.1302 - val_loss: 0.1292\n",
      "Epoch 3/10\n",
      "17516/17516 [==============================] - 21s - loss: 3.3529 - val_loss: 0.4656\n",
      "Epoch 4/10\n",
      "17516/17516 [==============================] - 20s - loss: 4.8874 - val_loss: 0.1863\n",
      "Epoch 5/10\n",
      "17516/17516 [==============================] - 21s - loss: 7.0445 - val_loss: 0.2356\n",
      "Epoch 6/10\n",
      "17516/17516 [==============================] - 21s - loss: 3.0626 - val_loss: 2.8542\n",
      "Epoch 7/10\n",
      "17516/17516 [==============================] - 20s - loss: 5.9324 - val_loss: 7.9464\n",
      "Epoch 8/10\n",
      "17516/17516 [==============================] - 20s - loss: 5.2262 - val_loss: 0.7999\n",
      "Epoch 9/10\n",
      "17516/17516 [==============================] - 20s - loss: 5.8150 - val_loss: 0.2200\n",
      "Epoch 10/10\n",
      "17516/17516 [==============================] - 20s - loss: 3.7678 - val_loss: 4.7489\n"
     ]
    }
   ],
   "source": [
    "m2 = Sequential()\n",
    "m2.add(Lambda(lambda x: x / 255.0, input_shape=(160, 320, 3)))\n",
    "m2.add(Flatten())\n",
    "m2.add(Dense(1))\n",
    "\n",
    "m2.compile(loss='mse', optimizer='adam')\n",
    "m2.fit(X_train, y_train, validation_split=0.2, shuffle=True)\n",
    "\n",
    "m2.save('m2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Center Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17516 samples, validate on 4379 samples\n",
      "Epoch 1/10\n",
      "17516/17516 [==============================] - 21s - loss: 4.4784 - val_loss: 16.1374\n",
      "Epoch 2/10\n",
      "17516/17516 [==============================] - 21s - loss: 1.9974 - val_loss: 8.7859\n",
      "Epoch 3/10\n",
      "17516/17516 [==============================] - 21s - loss: 3.7621 - val_loss: 1.8375\n",
      "Epoch 4/10\n",
      "17516/17516 [==============================] - 21s - loss: 4.2360 - val_loss: 0.4352\n",
      "Epoch 5/10\n",
      "17516/17516 [==============================] - 21s - loss: 2.3698 - val_loss: 5.8420\n",
      "Epoch 6/10\n",
      "17516/17516 [==============================] - 21s - loss: 5.0843 - val_loss: 1.3734\n",
      "Epoch 7/10\n",
      "17516/17516 [==============================] - 21s - loss: 1.8498 - val_loss: 7.1161\n",
      "Epoch 8/10\n",
      "17516/17516 [==============================] - 21s - loss: 3.4522 - val_loss: 4.0788s: 3.454\n",
      "Epoch 9/10\n",
      "17516/17516 [==============================] - 21s - loss: 3.1270 - val_loss: 2.9286\n",
      "Epoch 10/10\n",
      "17516/17516 [==============================] - 21s - loss: 1.5077 - val_loss: 0.7649\n"
     ]
    }
   ],
   "source": [
    "m3 = Sequential()\n",
    "m3.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "m3.add(Flatten())\n",
    "m3.add(Dense(1))\n",
    "\n",
    "m3.compile(loss='mse', optimizer='adam')\n",
    "m3.fit(X_train, y_train, validation_split=0.2, shuffle=True)\n",
    "\n",
    "m3.save('m3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdnpythonmachinelearning.azureedge.net/wp-content/uploads/2017/09/lenet-5.png?x64257)\n",
    "![](http://gpucomputing.shef.ac.uk/static/img/intro_dl_sharc_dgx1/mnist_lenet.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17516 samples, validate on 4379 samples\n",
      "Epoch 1/10\n",
      "17516/17516 [==============================] - 66s - loss: 0.3390 - val_loss: 0.1133\n",
      "Epoch 2/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0586 - val_loss: 0.0957\n",
      "Epoch 3/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0502 - val_loss: 0.0912\n",
      "Epoch 4/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0442 - val_loss: 0.0899\n",
      "Epoch 5/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0402 - val_loss: 0.1125\n",
      "Epoch 6/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0353 - val_loss: 0.0995\n",
      "Epoch 7/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0329 - val_loss: 0.0930\n",
      "Epoch 8/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0302 - val_loss: 0.1046\n",
      "Epoch 9/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0279 - val_loss: 0.0930\n",
      "Epoch 10/10\n",
      "17516/17516 [==============================] - 65s - loss: 0.0252 - val_loss: 0.0964\n"
     ]
    }
   ],
   "source": [
    "lenet = Sequential()\n",
    "lenet.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160, 320, 3)))\n",
    "lenet.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "lenet.add(MaxPooling2D())\n",
    "lenet.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "lenet.add(MaxPooling2D())\n",
    "lenet.add(Flatten())\n",
    "lenet.add(Dense(120))\n",
    "lenet.add(Dense(84))\n",
    "lenet.add(Dense(1))\n",
    "\n",
    "\n",
    "lenet.compile(loss='mse', optimizer='adam')\n",
    "lenet.fit(X_train, y_train, validation_split=0.2, shuffle=True)\n",
    "\n",
    "lenet.save('lenet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flipping Images Vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug, y_aug = [], []\n",
    "\n",
    "for X, y in zip(X_train_d, y_train_d):\n",
    "    X_aug.append(X)\n",
    "    y_aug.append(y)\n",
    "    X_aug.append(cv2.flip(X, 1))\n",
    "    y_aug.append(y * -1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-40a5749a3c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_aug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_aug, y_aug = np.array(X_aug), np.array(y_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43790, 160, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "aug_data = {\"features\" : X_aug,\"labels\" : y_aug}\n",
    "pickle.dump(aug_data, open( \"train_aug.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/10\n",
      "19286/19286 [==============================] - 49s - loss: 0.0682 - val_loss: 0.0214\n",
      "Epoch 2/10\n",
      "19286/19286 [==============================] - 46s - loss: 0.0142 - val_loss: 0.0208\n",
      "Epoch 3/10\n",
      "19286/19286 [==============================] - 46s - loss: 0.0119 - val_loss: 0.0187\n",
      "Epoch 4/10\n",
      "19286/19286 [==============================] - 46s - loss: 0.0106 - val_loss: 0.0180\n",
      "Epoch 5/10\n",
      "19286/19286 [==============================] - 46s - loss: 0.0098 - val_loss: 0.0195\n",
      "Epoch 6/10\n",
      "19286/19286 [==============================] - 46s - loss: 0.0090 - val_loss: 0.0175\n",
      "Epoch 7/10\n",
      "19286/19286 [==============================] - 46s - loss: 0.0086 - val_loss: 0.0184\n",
      "Epoch 8/10\n",
      "19286/19286 [==============================] - 47s - loss: 0.0083 - val_loss: 0.0184\n",
      "Epoch 9/10\n",
      "19286/19286 [==============================] - 46s - loss: 0.0081 - val_loss: 0.0190\n",
      "Epoch 10/10\n",
      "19286/19286 [==============================] - 46s - loss: 0.0077 - val_loss: 0.0187\n"
     ]
    }
   ],
   "source": [
    "lenet_aug = Sequential()\n",
    "lenet_aug.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160,320,3)))\n",
    "lenet_aug.add(Lambda(lambda x: x / 255.0 - 0.5))\n",
    "lenet_aug.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "lenet_aug.add(MaxPooling2D())\n",
    "lenet_aug.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "lenet_aug.add(MaxPooling2D())\n",
    "lenet_aug.add(Flatten())\n",
    "lenet_aug.add(Dense(120))\n",
    "lenet_aug.add(Dense(84))\n",
    "lenet_aug.add(Dense(1))\n",
    "\n",
    "lenet_aug.compile(loss='mse', optimizer='adam')\n",
    "lenet_aug.fit(X_train_d, y_train_d, validation_split=0.2, shuffle=True)\n",
    "\n",
    "lenet_aug.save('lenet_default_train.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nvidia End to End Model\n",
    "\n",
    "<img src=\"https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2016/08/cnn-architecture.png\" alt=\"Nvidia Network\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/5\n",
      "19200/19286 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.1804Epoch 00000: val_loss improved from -inf to 0.04424, saving model to nividia-improvement-00-0.18.hdf5\n",
      "19286/19286 [==============================] - 69s - loss: 0.0447 - acc: 0.1799 - val_loss: 0.0442 - val_acc: 0.1837\n",
      "Epoch 2/5\n",
      "19200/19286 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.1795Epoch 00001: val_loss did not improve\n",
      "19286/19286 [==============================] - 41s - loss: 0.0356 - acc: 0.1798 - val_loss: 0.0317 - val_acc: 0.1837\n",
      "Epoch 3/5\n",
      "19200/19286 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.1798Epoch 00002: val_loss did not improve\n",
      "19286/19286 [==============================] - 41s - loss: 0.0284 - acc: 0.1800 - val_loss: 0.0310 - val_acc: 0.1837\n",
      "Epoch 4/5\n",
      "19200/19286 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.1799Epoch 00003: val_loss did not improve\n",
      "19286/19286 [==============================] - 41s - loss: 0.0243 - acc: 0.1799 - val_loss: 0.0237 - val_acc: 0.1837\n",
      "Epoch 5/5\n",
      "19200/19286 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.1801Epoch 00004: val_loss did not improve\n",
      "19286/19286 [==============================] - 41s - loss: 0.0226 - acc: 0.1801 - val_loss: 0.0213 - val_acc: 0.1837\n"
     ]
    }
   ],
   "source": [
    "nvidia = Sequential()\n",
    "nvidia.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "nvidia.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "nvidia.add(Convolution2D(24, 5, 5, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Convolution2D(36, 5, 5, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Convolution2D(48, 5, 5, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Flatten())\n",
    "nvidia.add(Dense(100))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Dense(50))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Dense(10))\n",
    "nvidia.add(Dense(1))\n",
    "\n",
    "# Adamax, Adadelta, Adagrad, Adam, SGD, RMSprop\n",
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "nvidia.compile(loss='mse', optimizer=opt,  metrics=['accuracy'])\n",
    "\n",
    "filepath=\"nividia-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = nvidia.fit(X_train_d, y_train_d, validation_split=0.2, batch_size=128, nb_epoch=5, callbacks=callbacks_list, shuffle=True)\n",
    "\n",
    "nvidia.save('nvidia_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70a806b208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model MSE Loss')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Set', 'Validation Set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "samples = []\n",
    "with open('./default_data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                center_name = './default_data/IMG/' + batch_sample[0].split('/')[-1].strip()\n",
    "                left_name = './default_data/IMG/' + batch_sample[1].split('/')[-1].strip()\n",
    "                right_name = './default_data/IMG/'+ batch_sample[1].split('/')[-1].strip()\n",
    "                \n",
    "                # read in images from left and right cameras\n",
    "                center_image = cv2.imread(center_name)\n",
    "                left_image = cv2.imread(left_name)\n",
    "                right_image = cv2.imread(right_name)\n",
    "                \n",
    "                center_angle = float(batch_sample[3])\n",
    "                \n",
    "                # create adjusted steering measurements for the side camera images\n",
    "                correction = 0.2 # this is a parameter to tune\n",
    "                left_angle = center_angle + correction\n",
    "                right_angle = center_angle - correction\n",
    "                \n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            \n",
    "            yield shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14016/19284 [====================>.........] - ETA: 10s - loss: 0.0411 - acc: 0.1807"
     ]
    }
   ],
   "source": [
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "ngen = Sequential()\n",
    "ngen.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(160,320,3)))\n",
    "ngen.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "ngen.add(Convolution2D(24, 5, 5, subsample=(2, 2), activation='relu'))\n",
    "ngen.add(Convolution2D(36, 5, 5, subsample=(2, 2), activation='relu'))\n",
    "ngen.add(Convolution2D(48, 5, 5, subsample=(2, 2), activation='relu'))\n",
    "ngen.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "ngen.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "ngen.add(Flatten())\n",
    "ngen.add(Dense(100))\n",
    "ngen.add(Dense(50))\n",
    "ngen.add(Dense(10))\n",
    "ngen.add(Dense(1))\n",
    "\n",
    "ngen.compile(loss='mse', optimizer='adam',  metrics=['accuracy'])\n",
    "\n",
    "filepath=\"ngen-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "nvidia.fit_generator(train_generator, \n",
    "                     samples_per_epoch=len(train_samples) * 3, \n",
    "                     validation_data=validation_generator, \n",
    "                     nb_val_samples=len(validation_samples) * 3, \n",
    "                     nb_epoch=3)\n",
    "\n",
    "nvidia.save('ngen_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
